[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Kishor Das",
    "section": "",
    "text": "A litle bit about me."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Kishor Das",
    "section": "Education",
    "text": "Education\nUniversity of XYZ, City | Location | Sept 20XX - June 20XX"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Kishor Das",
    "section": "Experience",
    "text": "Experience\nWorkplace | Job title | April 20XX - present"
  },
  {
    "objectID": "blog/second-post/index.html",
    "href": "blog/second-post/index.html",
    "title": "Second Post",
    "section": "",
    "text": "Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.\nLorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Quis imperdiet massa tincidunt nunc pulvinar sapien et ligula. Amet cursus sit amet dictum sit amet. Eget duis at tellus at urna condimentum. Convallis aenean et tortor at risus viverra. Tincidunt ornare massa eget egestas purus viverra accumsan. Et malesuada fames ac turpis egestas. At imperdiet dui accumsan sit amet. Ut ornare lectus sit amet est placerat. Enim nulla aliquet porttitor lacus luctus accumsan tortor posuere. Duis ultricies lacus sed turpis tincidunt id aliquet risus. Mattis enim ut tellus elementum sagittis. Dui id ornare arcu odio ut. Natoque penatibus et magnis dis. Libero justo laoreet sit amet cursus sit. Sed faucibus turpis in eu. Tempus iaculis urna id volutpat lacus laoreet.\nPhasellus vestibulum lorem sed risus. Eget felis eget nunc lobortis mattis. Sit amet aliquam id diam maecenas ultricies. Egestas maecenas pharetra convallis posuere morbi. Etiam erat velit scelerisque in dictum non consectetur a erat. Cras fermentum odio eu feugiat pretium nibh ipsum consequat. Viverra accumsan in nisl nisi scelerisque. Et netus et malesuada fames ac. Amet tellus cras adipiscing enim eu turpis egestas pretium aenean. Eget lorem dolor sed viverra ipsum nunc aliquet. Ultrices dui sapien eget mi proin sed libero enim sed. Ultricies mi eget mauris pharetra et ultrices neque. Ipsum suspendisse ultrices gravida dictum. A arcu cursus vitae congue mauris rhoncus aenean vel. Gravida arcu ac tortor dignissim convallis. Nulla posuere sollicitudin aliquam ultrices."
  },
  {
    "objectID": "blog/third-post/index.html",
    "href": "blog/third-post/index.html",
    "title": "Third Blog Post",
    "section": "",
    "text": "The source for any page in your website could also be a Jupyter Notebook. This one is third-post/index.ipynb.\nHere’s an example I borrowed from the Seaborn docs:\n\nimport seaborn as sns\n\nsns.set_theme(style=\"whitegrid\")\n\n# Load the diamonds dataset\ndiamonds = sns.load_dataset(\"diamonds\")\n\n# Plot the distribution of clarity ratings, conditional on carat\nsns.displot(\n    data=diamonds,\n    x=\"carat\", hue=\"cut\",\n    kind=\"kde\", height=4, aspect=1.5,\n    multiple=\"fill\", clip=(0, None),\n    palette=\"ch:rot=-.25,hue=1,light=.75\",   \n)"
  },
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "Projects",
    "section": "",
    "text": "Predicting House Prices with Machine Learning\n\n\n\nPython\n\nMachine Learning\n\nData Cleaning\n\n\n\nThis project involves using machine learning algorithms to predict house prices based on various features such as location, size, and amenities. It includes data cleaning, feature engineering, and model selection.\n\n\n\nJan 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nCustomer Segmentation Using Clustering Techniques\n\n\n\nR\n\nMachine Learning\n\nClustering\n\nStatistical Modelling\n\n\n\nThis project focuses on segmenting customers into different groups based on their purchasing behavior and demographics. It uses clustering algorithms like K-means and hierarchical clustering to identify distinct customer segments.\n\n\n\nApr 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nVisualizing Global CO2 Emissions\n\n\n\nR\n\nData Visualization\n\nEnvironmental Science\n\n\n\nThis project involves creating visualizations to show trends in global CO2 emissions over time. It includes data extraction from public databases, data cleaning, and using visualization libraries to create interactive charts and graphs.\n\n\n\nJul 1, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/first-post/index.html",
    "href": "blog/first-post/index.html",
    "title": "First Post",
    "section": "",
    "text": "Sed risus ultricies tristique nulla aliquet. Neque volutpat ac tincidunt vitae semper quis lectus nulla.\nLorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Enim sed faucibus turpis in eu mi bibendum neque. Ac orci phasellus egestas tellus rutrum tellus pellentesque eu. Velit sed ullamcorper morbi tincidunt ornare massa. Sagittis id consectetur purus ut faucibus pulvinar elementum integer. Tincidunt nunc pulvinar sapien et ligula ullamcorper malesuada proin libero. Lobortis feugiat vivamus at augue eget arcu. Aliquam ut porttitor leo a diam sollicitudin tempor id eu. Mauris a diam maecenas sed enim ut sem viverra aliquet. Enim ut tellus elementum sagittis vitae et leo duis. Molestie at elementum eu facilisis sed odio morbi quis commodo. Sapien pellentesque habitant morbi tristique senectus. Quam vulputate dignissim suspendisse in est. Nulla pellentesque dignissim enim sit amet venenatis urna cursus eget.\nVelit aliquet sagittis id consectetur purus ut faucibus pulvinar elementum. Viverra mauris in aliquam sem fringilla ut morbi tincidunt augue. Tortor at auctor urna nunc id. Sit amet consectetur adipiscing elit duis tristique sollicitudin. Aliquet nibh praesent tristique magna sit amet purus. Tristique senectus et netus et malesuada fames ac turpis. Hac habitasse platea dictumst quisque. Auctor neque vitae tempus quam pellentesque nec nam aliquam. Ultrices tincidunt arcu non sodales neque sodales ut etiam. Iaculis at erat pellentesque adipiscing. Cras tincidunt lobortis feugiat vivamus. Nisi est sit amet facilisis magna etiam. Pharetra pharetra massa massa ultricies mi quis hendrerit. Vitae sapien pellentesque habitant morbi tristique senectus. Ornare aenean euismod elementum nisi quis eleifend quam adipiscing vitae."
  },
  {
    "objectID": "projects/project1.html",
    "href": "projects/project1.html",
    "title": "Predicting Hospital Readmissions",
    "section": "",
    "text": "library(tidyverse)",
    "crumbs": [
      "Projects",
      "Causal Inference Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "projects/project2.html",
    "href": "projects/project2.html",
    "title": "Genomic Data Clustering",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(cluster)\n\n# Simulate genomic expression data\nset.seed(42)\ngenomic_data &lt;- matrix(rnorm(200*50), nrow=200, ncol=50)\n\n# K-means clustering\nkmeans_result &lt;- kmeans(genomic_data, centers=3)\n\n# Plot cluster counts\ntable(kmeans_result$cluster)\n\n\n 1  2  3 \n74 63 63",
    "crumbs": [
      "Projects",
      "Causal Inference Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "projects/project3.html",
    "href": "projects/project3.html",
    "title": "Clinical Trial Survival Analysis",
    "section": "",
    "text": "library(survival) library(survminer)\n\nSimulate survival data\nset.seed(123) n &lt;- 200 time &lt;- rexp(n, rate = 0.1) status &lt;- rbinom(n, 1, 0.7) group &lt;- sample(c(“Treatment”, “Control”), n, replace = TRUE)\nsurv_object &lt;- Surv(time, status) fit &lt;- survfit(surv_object ~ group)\nggsurvplot(fit, data=data.frame(time,status,group), pval=TRUE, risk.table=TRUE)",
    "crumbs": [
      "Projects",
      "Clinical Trial Survival Analysis"
    ]
  },
  {
    "objectID": "projects/project4.html",
    "href": "projects/project4.html",
    "title": "EHR Text Mining",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidytext)\n\n# Simulate EHR notes\nehr_notes &lt;- tibble(\n  id = 1:5,\n  text = c(\"Patient has diabetes and hypertension.\",\n           \"No history of smoking. Normal vitals.\",\n           \"Severe asthma attack. Prescribed steroids.\",\n           \"High cholesterol, diabetes management ongoing.\",\n           \"Mild depression, follow-up in 2 weeks.\")\n)\n\ntokens &lt;- ehr_notes %&gt;%\n  unnest_tokens(word, text) %&gt;%\n  count(word, sort = TRUE)\n\ntokens\n\n# A tibble: 27 × 2\n   word            n\n   &lt;chr&gt;       &lt;int&gt;\n 1 diabetes        2\n 2 2               1\n 3 and             1\n 4 asthma          1\n 5 attack          1\n 6 cholesterol     1\n 7 depression      1\n 8 follow          1\n 9 has             1\n10 high            1\n# ℹ 17 more rows",
    "crumbs": [
      "Projects",
      "EHR Text Mining"
    ]
  },
  {
    "objectID": "projects/project5.html",
    "href": "projects/project5.html",
    "title": "COVID-19 Dashboard",
    "section": "",
    "text": "library(tidyverse) library(plotly)\n\nSimulate COVID data\ncovid_data &lt;- tibble( date = seq.Date(as.Date(“2020-01-01”), by=“month”, length.out=24), cases = cumsum(rpois(24, lambda=500)) )\nplot_ly(covid_data, x=~date, y=~cases, type=‘scatter’, mode=‘lines+markers’)",
    "crumbs": [
      "Projects",
      "COVID-19 Dashboard"
    ]
  },
  {
    "objectID": "projects/project1.html#loading-packages",
    "href": "projects/project1.html#loading-packages",
    "title": "Predicting Hospital Readmissions",
    "section": "",
    "text": "library(tidyverse)",
    "crumbs": [
      "Projects",
      "Causal Inference Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "projects/project1.html#conclusion",
    "href": "projects/project1.html#conclusion",
    "title": "Predicting Hospital Readmissions",
    "section": "Conclusion",
    "text": "Conclusion",
    "crumbs": [
      "Projects",
      "Causal Inference Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Kishor Das",
    "section": "",
    "text": "About Me\nI’m a master’s graduate in Health Data Science passionate about\nturning healthcare data into actionable insights.\nI specialize in:\nR and Python programming, Predictive modeling and machine learning, Clinical research analytics and Genomics and population health studies.\nOutside work, I love data storytelling, open science, and exploring new tools for health informatics."
  },
  {
    "objectID": "cv.html",
    "href": "cv.html",
    "title": "Curriculum Vitae",
    "section": "",
    "text": "Download my PDF CV.\n\n\n\nMSc in Health Data Science, University XYZ, 2025\nBSc in Biostatistics, University ABC, 2023\n\n\n\n\n\nProgramming: R, Python, SQL\nTools: GitHub, Quarto, R Markdown, Shiny\nTechniques: Predictive Modeling, Survival Analysis, NLP, Data Visualization"
  },
  {
    "objectID": "cv.html#education",
    "href": "cv.html#education",
    "title": "Curriculum Vitae",
    "section": "",
    "text": "MSc in Health Data Science, University XYZ, 2025\nBSc in Biostatistics, University ABC, 2023"
  },
  {
    "objectID": "cv.html#skills",
    "href": "cv.html#skills",
    "title": "Curriculum Vitae",
    "section": "",
    "text": "Programming: R, Python, SQL\nTools: GitHub, Quarto, R Markdown, Shiny\nTechniques: Predictive Modeling, Survival Analysis, NLP, Data Visualization"
  },
  {
    "objectID": "projects/project1.html#simulating-a-dataset",
    "href": "projects/project1.html#simulating-a-dataset",
    "title": "Predicting Hospital Readmissions",
    "section": "Simulating a dataset",
    "text": "Simulating a dataset\n\nset.seed(123)\nn &lt;- 500\nhospital_data &lt;- tibble(\n  age = rnorm(n, 65, 10),\n  comorbidities = sample(0:5, n, replace = TRUE),\n  readmitted = rbinom(n, 1, 0.3)\n)\n\n# Logistic regression\nmodel &lt;- glm(readmitted ~ age + comorbidities, data = hospital_data, family = \"binomial\")\n\nsummary(model)\n\n\nCall:\nglm(formula = readmitted ~ age + comorbidities, family = \"binomial\", \n    data = hospital_data)\n\nCoefficients:\n               Estimate Std. Error z value Pr(&gt;|z|)  \n(Intercept)   -1.152634   0.682370  -1.689   0.0912 .\nage            0.003201   0.010071   0.318   0.7506  \ncomorbidities  0.029580   0.056949   0.519   0.6035  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 607.44  on 499  degrees of freedom\nResidual deviance: 607.06  on 497  degrees of freedom\nAIC: 613.06\n\nNumber of Fisher Scoring iterations: 4",
    "crumbs": [
      "Projects",
      "Causal Inference Projects",
      "Project 1"
    ]
  }
]